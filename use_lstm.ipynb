{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "\n",
    "in_windows = 2\n",
    "out_windows = 3  \n",
    "batch_size =30 \n",
    "inp = torch.randn((batch_size,in_windows))\n",
    "class lstm(torch.nn.Module):\n",
    "    def __init__(self,in_windows,out_windows, hidden_size, hidden_num_layers):\n",
    "        super(lstm, self).__init__()\n",
    "        # 定义LSTM\n",
    "        self.lstm = torch.nn.LSTM(1, hidden_size, hidden_num_layers)\n",
    "        # 定义回归层网络，输入的特征维度等于LSTM的输出，输出维度为1\n",
    "        self.reg = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size, 50),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(50, 25),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(25, out_windows),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.transpose(-1,-2)\n",
    "        x = x.view(x.shape[0],x.shape[1],1)\n",
    "        x,(h,c)= self.lstm(x)\n",
    "        return self.reg(h[-1])\n",
    "\n",
    "model = lstm(in_windows,out_windows,100,3)\n",
    "print(model(inp).shape)    \n",
    "\n",
    "# def train_lstm(data,in_windows,out_windows,train_num,epoch_num):\n",
    "#     X = [] \n",
    "#     y = [] \n",
    "#     L = len(data)\n",
    "#     for i in range(L):\n",
    "#         if i+in_windows+out_windows > L:\n",
    "#             break\n",
    "#         X.append(data[i:i+in_windows])\n",
    "#         y.append(data[i+in_windows:i+in_windows+out_windows])\n",
    "#     X = np.array(X)\n",
    "#     y = np.array(y)\n",
    "#     X_train,y_train,X_test,y_test= X[:train_num],y[:train_num],X[train_num:],y[train_num:]\n",
    "#     model = lstm(out_windows=out_windows,hidden_size=100,hidden_num_layers=3)\n",
    "#     optimizer = torch.optim.AdamW(model.parameters(),lr=0.1)\n",
    "#     lossfn = torch.nn.MSELoss()\n",
    "#     for epoch_idx in range(epoch_num):\n",
    "#         optimizer.zero_grad()\n",
    "#         out = model(X_train)\n",
    "#         error = lossfn(out,y_train)\n",
    "#         print(\"epoch_%d:%s\"%(epoch_idx,error))\n",
    "#         error.backward()\n",
    "#         optimizer.step()\n",
    "#     model.eval()\n",
    "#     test_pred = model(X_test)\n",
    "#     print(test_pred)\n",
    "#     print(\"xgb r2:\",r2_score(y_test,test_pred))\n",
    "#     print(\"xgb mse:\",mean_squared_error(y_test,test_pred))\n",
    "#     print(\"xgb mae:\",mean_absolute_error(y_test,test_pred))\n",
    "#     train_pred = model(X_train)\n",
    "#     res = []\n",
    "#     for i in train_pred.numpy() :\n",
    "#         res.append(i[0])\n",
    "#     for i in test_pred.numpy():\n",
    "#         res.append(i[0])\n",
    "#     return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
